{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def enumerate_paths(n, n_branches):\n",
    "    \"\"\"\n",
    "    Enumerate all paths (from the root to the n-th decision node) in a perfect \n",
    "    balanced k-ary tree with a fixed number of decisions (n) and fixed number \n",
    "    of branches (n_branches).\n",
    "\n",
    "    The tree is assumed to be stored in \"heap order\":\n",
    "       - The root is at index 0.\n",
    "       - For a node at index i, its b-th child (with b in {0, ..., n_branches-1}) \n",
    "         is at index: n_branches * i + (b + 1).\n",
    "\n",
    "    Parameters:\n",
    "      n (int): Number of decision layers (i.e., the path length).\n",
    "      n_branches (int): Number of branches (children) per node (>=2).\n",
    "\n",
    "    Returns:\n",
    "      node_paths (torch.LongTensor): Tensor of shape (n_all_paths, n) with the indices \n",
    "                                     of nodes where decisions occur.\n",
    "      branch_paths (torch.LongTensor): Tensor of shape (n_all_paths, n) with the branch \n",
    "                                       choices made at each corresponding node.\n",
    "    \"\"\"\n",
    "    # Generate all possible sequences of branch choices, where each sequence is of length n.\n",
    "    branch_sequences = list(itertools.product(range(n_branches), repeat=n))\n",
    "    node_paths = []\n",
    "    branch_paths = []\n",
    "    \n",
    "    # For each branch choice sequence, compute the corresponding node indices.\n",
    "    for seq in branch_sequences:\n",
    "        nodes = [0]  # The first decision is always at the root (index 0).\n",
    "        # For each decision (except the last one, because we only need the node where the decision is made)\n",
    "        # we compute the next node index.\n",
    "        for i in range(1, n):\n",
    "            current_node = nodes[i-1]\n",
    "            branch_choice = seq[i-1]\n",
    "            next_node = n_branches * current_node + (branch_choice + 1)\n",
    "            nodes.append(next_node)\n",
    "        # Append the list of node indices and branch choices for this path.\n",
    "        node_paths.append(nodes)\n",
    "        branch_paths.append(list(seq))\n",
    "    \n",
    "    # Convert the lists to PyTorch tensors.\n",
    "    node_paths = torch.tensor(node_paths, dtype=torch.long)    # shape: (n_all_paths, n)\n",
    "    branch_paths = torch.tensor(branch_paths, dtype=torch.long)  # shape: (n_all_paths, n)\n",
    "    \n",
    "    return node_paths, branch_paths\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    n = 3           # number of decision layers\n",
    "    n_branches = 3  # for a ternary tree (you can set this to any integer >= 2)\n",
    "\n",
    "    node_ids, branch_ids = enumerate_paths(n, n_branches)\n",
    "    print(\"Node indices:\\n\", node_ids)\n",
    "    print(\"Branch choices:\\n\", branch_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of experts: 6377292\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'6.08 MB'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def estimate_memory(n_branch, n_layers, dtype=torch.int8):\n",
    "    elements = (n_branch ** n_layers) * n_layers\n",
    "    bytes_per_element = torch.tensor(0, dtype=dtype).element_size()\n",
    "    print(f'number of experts: {elements}')\n",
    "    return f\"{(elements * bytes_per_element)/(1024**2):.2f} MB\"\n",
    "estimate_memory(3,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_probabilities(prob_tensor, node_paths, branch_paths):\n",
    "    selected_probs = prob_tensor[:, node_paths, branch_paths]\n",
    "    return selected_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Parameters for the tree.\n",
    "    n_layers = 3        # number of decision layers (path length)\n",
    "    n_branches = 2      # number of branches per node (e.g., a ternary tree)\n",
    "    \n",
    "    # Get the index tensors from enumerate_paths.\n",
    "    node_paths, branch_paths = enumerate_paths(n_layers, n_branches)\n",
    "    print(\"node_paths shape:\", node_paths.shape)   # Expected: (n_branches**n_layers, n_layers)\n",
    "    print(\"branch_paths shape:\", branch_paths.shape)  # Expected: (n_branches**n_layers, n_layers)\n",
    "    \n",
    "    # Create an example probability tensor.\n",
    "    # For instance, assume we have n_tokens tokens.\n",
    "    n_tokens = 1\n",
    "    # Ensure that the number of nodes is at least (max(node_paths) + 1)\n",
    "    n_nodes = node_paths.max().item() + 1\n",
    "    # Construct a probability tensor of shape (n_tokens, n_nodes, n_branches)\n",
    "    prob_tensor = torch.rand(n_tokens, n_nodes, n_branches)\n",
    "    \n",
    "    expert_indices = node_paths * n_branches + branch_paths\n",
    "    \n",
    "    # Use the select_probabilities function to get the tensor of selected probabilities.\n",
    "    selected_probs = select_probabilities(prob_tensor, node_paths, branch_paths)\n",
    "    print(\"selected_probs shape:\", selected_probs.shape)  # Expected: (n_tokens, n_all_paths, n_layers)\n",
    "    print(expert_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def compute_token_expert_weights(expert_indices, rel_weights, n_experts):\n",
    "    \"\"\"\n",
    "    Compute per-token weights for each expert.\n",
    "\n",
    "    Parameters:\n",
    "      expert_indices (torch.LongTensor): shape (n_tokens, n_paths, n_layers)\n",
    "          Each element is the index (in [0, n_experts)) of the expert chosen.\n",
    "      rel_weights (torch.Tensor): shape (n_tokens, n_paths, n_layers)\n",
    "          The relative weight corresponding to each routing decision.\n",
    "      n_experts (int): Total number of experts.\n",
    "\n",
    "    Returns:\n",
    "      token_expert_weights (torch.Tensor): shape (n_tokens, n_experts)\n",
    "          For each token and each expert, this contains the sum of weights from\n",
    "          all routing decisions that selected that expert.\n",
    "    \"\"\"\n",
    "    # One-hot encode the expert indices.\n",
    "    # Resulting shape: (n_tokens, n_paths, n_layers, n_experts)\n",
    "    one_hot = F.one_hot(expert_indices, num_classes=n_experts)\n",
    "\n",
    "    # Multiply by the relative weights.\n",
    "    # rel_weights.unsqueeze(-1) has shape (n_tokens, n_paths, n_layers, 1)\n",
    "    weighted_one_hot = one_hot * rel_weights.unsqueeze(-1)\n",
    "\n",
    "    # Sum over the n_paths and n_layers dimensions to obtain per-token weights for each expert.\n",
    "    # Resulting shape: (n_tokens, n_experts)\n",
    "    token_expert_weights = weighted_one_hot.sum(dim=(1, 2))\n",
    "    \n",
    "    return token_expert_weights\n",
    "\n",
    "# =======================\n",
    "# Example usage:\n",
    "# =======================\n",
    "if __name__ == \"__main__\":\n",
    "    # Example dimensions.\n",
    "    n_tokens = 2\n",
    "    n_paths  = 2\n",
    "    n_layers = 2\n",
    "    n_experts = 2\n",
    "\n",
    "    # Create random expert indices (integers in [0, n_experts))\n",
    "    expert_indices = torch.randint(0, n_experts, (n_tokens, n_paths, n_layers))\n",
    "\n",
    "    # Create random relative weights (for example, between 0 and 1)\n",
    "    rel_weights = torch.rand(n_tokens, n_paths, n_layers)\n",
    "\n",
    "    # Compute the token-expert weights\n",
    "    token_expert_weights = compute_token_expert_weights(expert_indices, rel_weights, n_experts)\n",
    "    print(\"Token-Expert Weights Shape:\", token_expert_weights.shape)\n",
    "    print(token_expert_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def get_expert_layer(index, branch_size):\n",
    "    \"\"\"\n",
    "    Given the expert's index (starting at 0) and the branch size (n),\n",
    "    returns the layer number on which the expert is located.\n",
    "    \n",
    "    For branch_size n > 1, layer L contains n^L experts, and\n",
    "    the cumulative number of experts up to layer L is:\n",
    "    \n",
    "        T(L) = n + n^2 + ... + n^L = n * (n^L - 1) / (n - 1)\n",
    "    \n",
    "    The layer L is the smallest integer satisfying:\n",
    "    \n",
    "        index < T(L)\n",
    "    \n",
    "    This function uses the formula:\n",
    "    \n",
    "        L = floor( log_n( 1 + ((n - 1) * index) / n ) ) + 1\n",
    "    \n",
    "    If branch_size == 1, the tree is a chain, and expert at index i\n",
    "    is simply in layer i + 1.\n",
    "    \"\"\"\n",
    "    if branch_size == 1:\n",
    "        return index + 1  # Each layer has 1 expert in this special case.\n",
    "\n",
    "    # Calculate the expression inside the logarithm.\n",
    "    value = 1 + ((branch_size - 1) * index) / branch_size\n",
    "    # Use math.log with base branch_size.\n",
    "    layer = math.floor(math.log(value, branch_size)) + 1\n",
    "    return layer\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    branch_size = 1  # For example, each node has 3 branches\n",
    "    test_indices = [0, 1, 2, 3, 4, 5, 6,7,8,9,10,11,12,13,14,15,16]\n",
    "\n",
    "    for i in test_indices:\n",
    "        layer = get_expert_layer(i, branch_size)\n",
    "        print(f\"Expert with index {i} is in layer {layer}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
