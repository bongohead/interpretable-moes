{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node indices:\n",
      " tensor([[ 0,  1,  4],\n",
      "        [ 0,  1,  4],\n",
      "        [ 0,  1,  4],\n",
      "        [ 0,  1,  5],\n",
      "        [ 0,  1,  5],\n",
      "        [ 0,  1,  5],\n",
      "        [ 0,  1,  6],\n",
      "        [ 0,  1,  6],\n",
      "        [ 0,  1,  6],\n",
      "        [ 0,  2,  7],\n",
      "        [ 0,  2,  7],\n",
      "        [ 0,  2,  7],\n",
      "        [ 0,  2,  8],\n",
      "        [ 0,  2,  8],\n",
      "        [ 0,  2,  8],\n",
      "        [ 0,  2,  9],\n",
      "        [ 0,  2,  9],\n",
      "        [ 0,  2,  9],\n",
      "        [ 0,  3, 10],\n",
      "        [ 0,  3, 10],\n",
      "        [ 0,  3, 10],\n",
      "        [ 0,  3, 11],\n",
      "        [ 0,  3, 11],\n",
      "        [ 0,  3, 11],\n",
      "        [ 0,  3, 12],\n",
      "        [ 0,  3, 12],\n",
      "        [ 0,  3, 12]])\n",
      "Branch choices:\n",
      " tensor([[0, 0, 0],\n",
      "        [0, 0, 1],\n",
      "        [0, 0, 2],\n",
      "        [0, 1, 0],\n",
      "        [0, 1, 1],\n",
      "        [0, 1, 2],\n",
      "        [0, 2, 0],\n",
      "        [0, 2, 1],\n",
      "        [0, 2, 2],\n",
      "        [1, 0, 0],\n",
      "        [1, 0, 1],\n",
      "        [1, 0, 2],\n",
      "        [1, 1, 0],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 2],\n",
      "        [1, 2, 0],\n",
      "        [1, 2, 1],\n",
      "        [1, 2, 2],\n",
      "        [2, 0, 0],\n",
      "        [2, 0, 1],\n",
      "        [2, 0, 2],\n",
      "        [2, 1, 0],\n",
      "        [2, 1, 1],\n",
      "        [2, 1, 2],\n",
      "        [2, 2, 0],\n",
      "        [2, 2, 1],\n",
      "        [2, 2, 2]])\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import torch\n",
    "\n",
    "def enumerate_paths(n, n_branches):\n",
    "    \"\"\"\n",
    "    Enumerate all paths (from the root to the n-th decision node) in a perfect \n",
    "    balanced k-ary tree with a fixed number of decisions (n) and fixed number \n",
    "    of branches (n_branches).\n",
    "\n",
    "    The tree is assumed to be stored in \"heap order\":\n",
    "       - The root is at index 0.\n",
    "       - For a node at index i, its b-th child (with b in {0, ..., n_branches-1}) \n",
    "         is at index: n_branches * i + (b + 1).\n",
    "\n",
    "    Parameters:\n",
    "      n (int): Number of decision layers (i.e., the path length).\n",
    "      n_branches (int): Number of branches (children) per node (>=2).\n",
    "\n",
    "    Returns:\n",
    "      node_paths (torch.LongTensor): Tensor of shape (n_all_paths, n) with the indices \n",
    "                                     of nodes where decisions occur.\n",
    "      branch_paths (torch.LongTensor): Tensor of shape (n_all_paths, n) with the branch \n",
    "                                       choices made at each corresponding node.\n",
    "    \"\"\"\n",
    "    # Generate all possible sequences of branch choices, where each sequence is of length n.\n",
    "    branch_sequences = list(itertools.product(range(n_branches), repeat=n))\n",
    "    node_paths = []\n",
    "    branch_paths = []\n",
    "    \n",
    "    # For each branch choice sequence, compute the corresponding node indices.\n",
    "    for seq in branch_sequences:\n",
    "        nodes = [0]  # The first decision is always at the root (index 0).\n",
    "        # For each decision (except the last one, because we only need the node where the decision is made)\n",
    "        # we compute the next node index.\n",
    "        for i in range(1, n):\n",
    "            current_node = nodes[i-1]\n",
    "            branch_choice = seq[i-1]\n",
    "            next_node = n_branches * current_node + (branch_choice + 1)\n",
    "            nodes.append(next_node)\n",
    "        # Append the list of node indices and branch choices for this path.\n",
    "        node_paths.append(nodes)\n",
    "        branch_paths.append(list(seq))\n",
    "    \n",
    "    # Convert the lists to PyTorch tensors.\n",
    "    node_paths = torch.tensor(node_paths, dtype=torch.long)    # shape: (n_all_paths, n)\n",
    "    branch_paths = torch.tensor(branch_paths, dtype=torch.long)  # shape: (n_all_paths, n)\n",
    "    \n",
    "    return node_paths, branch_paths\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    n = 3           # number of decision layers\n",
    "    n_branches = 3  # for a ternary tree (you can set this to any integer >= 2)\n",
    "\n",
    "    node_ids, branch_ids = enumerate_paths(n, n_branches)\n",
    "    print(\"Node indices:\\n\", node_ids)\n",
    "    print(\"Branch choices:\\n\", branch_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'66505.13 MB'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def estimate_memory(n_branch, n_layers, dtype=torch.int8):\n",
    "    elements = (n_branch ** n_layers) * n_layers\n",
    "    bytes_per_element = torch.tensor(0, dtype=dtype).element_size()\n",
    "    return f\"{(elements * bytes_per_element)/(1024**2):.2f} MB\"\n",
    "estimate_memory(3,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_probabilities(prob_tensor, node_paths, branch_paths):\n",
    "    selected_probs = prob_tensor[:, node_paths, branch_paths]\n",
    "    return selected_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_paths shape: torch.Size([8, 3])\n",
      "branch_paths shape: torch.Size([8, 3])\n",
      "selected_probs shape: torch.Size([1, 8, 3])\n",
      "tensor([[ 0,  2,  6],\n",
      "        [ 0,  2,  7],\n",
      "        [ 0,  3,  8],\n",
      "        [ 0,  3,  9],\n",
      "        [ 1,  4, 10],\n",
      "        [ 1,  4, 11],\n",
      "        [ 1,  5, 12],\n",
      "        [ 1,  5, 13]])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Parameters for the tree.\n",
    "    n_layers = 3        # number of decision layers (path length)\n",
    "    n_branches = 2      # number of branches per node (e.g., a ternary tree)\n",
    "    \n",
    "    # Get the index tensors from enumerate_paths.\n",
    "    node_paths, branch_paths = enumerate_paths(n_layers, n_branches)\n",
    "    print(\"node_paths shape:\", node_paths.shape)   # Expected: (n_branches**n_layers, n_layers)\n",
    "    print(\"branch_paths shape:\", branch_paths.shape)  # Expected: (n_branches**n_layers, n_layers)\n",
    "    \n",
    "    # Create an example probability tensor.\n",
    "    # For instance, assume we have n_tokens tokens.\n",
    "    n_tokens = 1\n",
    "    # Ensure that the number of nodes is at least (max(node_paths) + 1)\n",
    "    n_nodes = node_paths.max().item() + 1\n",
    "    # Construct a probability tensor of shape (n_tokens, n_nodes, n_branches)\n",
    "    prob_tensor = torch.rand(n_tokens, n_nodes, n_branches)\n",
    "    \n",
    "    expert_indices = node_paths * n_branches + branch_paths\n",
    "    \n",
    "    # Use the select_probabilities function to get the tensor of selected probabilities.\n",
    "    selected_probs = select_probabilities(prob_tensor, node_paths, branch_paths)\n",
    "    print(\"selected_probs shape:\", selected_probs.shape)  # Expected: (n_tokens, n_all_paths, n_layers)\n",
    "    print(expert_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token-Expert Weights Shape: torch.Size([2, 2])\n",
      "tensor([[1.0091, 0.7825],\n",
      "        [1.9803, 0.1404]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def compute_token_expert_weights(expert_indices, rel_weights, n_experts):\n",
    "    \"\"\"\n",
    "    Compute per-token weights for each expert.\n",
    "\n",
    "    Parameters:\n",
    "      expert_indices (torch.LongTensor): shape (n_tokens, n_paths, n_layers)\n",
    "          Each element is the index (in [0, n_experts)) of the expert chosen.\n",
    "      rel_weights (torch.Tensor): shape (n_tokens, n_paths, n_layers)\n",
    "          The relative weight corresponding to each routing decision.\n",
    "      n_experts (int): Total number of experts.\n",
    "\n",
    "    Returns:\n",
    "      token_expert_weights (torch.Tensor): shape (n_tokens, n_experts)\n",
    "          For each token and each expert, this contains the sum of weights from\n",
    "          all routing decisions that selected that expert.\n",
    "    \"\"\"\n",
    "    # One-hot encode the expert indices.\n",
    "    # Resulting shape: (n_tokens, n_paths, n_layers, n_experts)\n",
    "    one_hot = F.one_hot(expert_indices, num_classes=n_experts)\n",
    "\n",
    "    # Multiply by the relative weights.\n",
    "    # rel_weights.unsqueeze(-1) has shape (n_tokens, n_paths, n_layers, 1)\n",
    "    weighted_one_hot = one_hot * rel_weights.unsqueeze(-1)\n",
    "\n",
    "    # Sum over the n_paths and n_layers dimensions to obtain per-token weights for each expert.\n",
    "    # Resulting shape: (n_tokens, n_experts)\n",
    "    token_expert_weights = weighted_one_hot.sum(dim=(1, 2))\n",
    "    \n",
    "    return token_expert_weights\n",
    "\n",
    "# =======================\n",
    "# Example usage:\n",
    "# =======================\n",
    "if __name__ == \"__main__\":\n",
    "    # Example dimensions.\n",
    "    n_tokens = 2\n",
    "    n_paths  = 2\n",
    "    n_layers = 2\n",
    "    n_experts = 2\n",
    "\n",
    "    # Create random expert indices (integers in [0, n_experts))\n",
    "    expert_indices = torch.randint(0, n_experts, (n_tokens, n_paths, n_layers))\n",
    "\n",
    "    # Create random relative weights (for example, between 0 and 1)\n",
    "    rel_weights = torch.rand(n_tokens, n_paths, n_layers)\n",
    "\n",
    "    # Compute the token-expert weights\n",
    "    token_expert_weights = compute_token_expert_weights(expert_indices, rel_weights, n_experts)\n",
    "    print(\"Token-Expert Weights Shape:\", token_expert_weights.shape)\n",
    "    print(token_expert_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 0],\n",
       "         [0, 0]],\n",
       "\n",
       "        [[0, 0],\n",
       "         [1, 0]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7825, 0.1712],\n",
       "         [0.8262, 0.0117]],\n",
       "\n",
       "        [[0.7879, 0.6615],\n",
       "         [0.1404, 0.5309]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
